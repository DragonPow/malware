# Importing necessary libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import time
import os
import pandas as pd
from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
import utils
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
import numpy as np

def main():
    # Assign command line arguments to variables
    args = utils.parse_arguments()
    selection_group_features = list[str](args.selection_group_features)
    data_dir = str(args.data_dir)
    model_dir = str(args.model_dir)
    file_name = str(args.dataset_filename)
    top_n_labels = int(args.top_n_labels)
    is_binary = args.is_binary

    # build testcase name from args
    # convert selection_group_features from AbdDef to abd_def
    name_testcase_group_feature = '_'.join([utils.camel_to_snake(feature) for feature in selection_group_features])
    testcase_name = f"{name_testcase_group_feature or 'all_feature'}__{top_n_labels if top_n_labels != -1 else 'all'}_labels__{'binary' if is_binary else 'multi'}"
    print(f'Testcase name: {testcase_name}')
    # Build the path to the dataset file
    file_csv = os.path.join(data_dir, file_name)

    # Read dataset from a file
    df = pd.read_csv(file_csv, sep='|')
    print('Read dataset successfully')
    print(df.shape)

    # process task is binary or multi
    if is_binary:
        # convert all label not NaN to 1, else 0
        df['label'] = df['label'].apply(lambda x: 1 if pd.notnull(x) else 0)
    else:
        # convert label NaN to 'benign'
        df['label'] = df['label'].fillna('benign')
        # get top n labels
        df = utils.get_top_labels(df, top_n_labels)

    # get X, y from df
    X = utils.get_X(df, selection_group_features)
    y = df['label']
    print('Class', y.unique())

    # Convert y to numerical values uing LabelEncoder
    label_encoder = LabelEncoder()
    # index_label_benign = 0
    if not is_binary:
        y = label_encoder.fit_transform(y)
        # index_label_benign = label_encoder.transform(["benign"])
    labels = np.unique(y)

    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # list models is common classifier mode, with naive bayes, random forest, svm, knn, decision tree
    models = [
        ('gaussian_bayes', GaussianNB()),
        ('bernoulli_bayes', BernoulliNB()),
        # ('Multinomial Bayes', MultinomialNB()),
        ('random_forest', RandomForestClassifier(n_estimators=100)),
        ('svm', SVC()),
        ('knn', KNeighborsClassifier()),
        ('decision_tree', DecisionTreeClassifier())
    ]

    # if not exists model_dir, create it
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
        print(f'Create {model_dir} successfully')

    # if not exists result csv file, create it
    csv_resul_file_path = os.path.join(model_dir, f'result.csv')
    if not os.path.exists(csv_resul_file_path):
        f = open(csv_resul_file_path, 'w')
        #create csv file with separator ','
        f.write('testcase_name,model,selection_groups,top_n_labels,is_binary,training_time,testing_time,accuracy,f1_score,precision,recall\n')
        print('Create csv file successfully')
    else:
        f = open(csv_resul_file_path, 'a')
        print('Csv file existed')

    # using pipeline to train and test model
    print('\nSTART TRAINING AND TESTING MODELS')
    print('-'*20 + '\n')
    for name, model in models:
        print(f'Running {name} model')
        start = time.time()
        model.fit(X_train, y_train)
        end = time.time()
        training_time = end - start
        print(f'{name} - Training time: {end - start} seconds')

        start = time.time()
        score = model.score(X_test, y_test)
        end = time.time()
        testting_time = end - start
        print(f'{name} - Testing time: {end - start} seconds')

        # get metrics of model: accuracy, f1_score, precision, recall using lib metrics
        m = utils.get_metrics(model, X_test, y_test, labels)

        # show number benign from label_encoder and y_test  
        # y_pred = model.predict(X_test)
        # print(f'Number of benign: {len(y_test[y_test == index_label_benign])}')
        # print(f'Number of benign 2: {len(y_pred[y_pred == index_label_benign])}')
        # for i in range(m['confusion_matrix'].shape[0]):
        #     print(f'{label_encoder.inverse_transform([i])[0]}: {m["confusion_matrix"][i][i]}')
        # if name == 'random_forest':
        #     break

        roc_auc = None
        fpr = None
        tpr = None
        if is_binary:
            try:
                # curve of model
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
                roc_auc = metrics.auc(fpr, tpr)
            except Exception as e:
                print(f'Error when calculate roc_auc: {e}')

        # store all value need to metrics, compute, compare,...
        data_store = {
            'options': {
                'model': name,
                'selection_group_features': selection_group_features or None,
                'top_n_labels': top_n_labels,
                'is_binary': is_binary,
                'label_encoder': label_encoder
            },
            'training_time': training_time,
            'testing_time': testting_time,
            'metrics': m,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # write result to csv file
        f.write(f'{testcase_name},{name},{data_store["options"]['selection_group_features']},{top_n_labels},{is_binary},{data_store["training_time"]},{data_store["testing_time"]},{m["accuracy"]},{m["f1"]},{m["precision"]},{m["recall"]}\n')
        print('Write result to csv file successfully')

        # Save the model to disk
        model_file = os.path.join(model_dir, f'{testcase_name}__{name}.pkl')
        datasources_file = os.path.join(model_dir, f'{testcase_name}__{name}__datasources.pkl')
        utils.save_model(model, model_file)
        utils.save_model(data_store, datasources_file)
        print(f'Saved model to {model_file}')
        print('-'*20 + '\n')

    # close csv file
    print('Close csv file')
    f.close()
        
    # classes = df['label'].unique()
    # Plot confusion matrix, using utils.plot_confusion_matrix
    # utils.plot_confusion_matrix(models, X_test, y_test, classes, title=f'{name} - Confusion matrix')
        
if __name__ == '__main__':
    main()
    print('DONE')